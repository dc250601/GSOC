{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d4ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coat import *\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12a87a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ML_RTC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "image_size = (128,128)\n",
    "in_channels = 3\n",
    "num_blocks = [2, 2, 6, 14, 2]\n",
    "channels = [64, 96, 192, 384, 768]\n",
    "num_classes = 1\n",
    "\n",
    "model = CoAtNet(image_size = image_size,\n",
    "                         in_channels = in_channels,\n",
    "                         num_blocks = num_blocks,\n",
    "                         channels = channels,\n",
    "                         num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918683f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./model_epoch_6_run_0.pt\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180a0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.RandomRotation(60),\n",
    "                                transforms.ToTensor()\n",
    "                               ])\n",
    "dataset_Train = datasets.ImageFolder(f'./Data_small_50/Train/', transform=train_transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_Train, batch_size=128, shuffle=True, drop_last = True, num_workers=4, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e761cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4973dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(dataloader_train))\n",
    "outputs = model(image)\n",
    "loss = criterion(outputs, label.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be4d5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "#torch.nn.utils.clip_grad_norm_(list(model.parameters())[-1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1402167c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3483)\n",
      "tensor(0.0398)\n",
      "tensor(0.0489)\n",
      "tensor(0.1934)\n",
      "tensor(0.0615)\n",
      "tensor(0.0569)\n",
      "tensor(0.2294)\n",
      "tensor(0.0169)\n",
      "tensor(2.1401e-08)\n",
      "tensor(0.1131)\n",
      "tensor(0.0039)\n",
      "tensor(0.0089)\n",
      "tensor(0.1108)\n",
      "tensor(0.0157)\n",
      "tensor(0.0116)\n",
      "tensor(0.0133)\n",
      "tensor(0.0245)\n",
      "tensor(0.0878)\n",
      "tensor(0.0338)\n",
      "tensor(0.0641)\n",
      "tensor(0.0278)\n",
      "tensor(2.2162e-08)\n",
      "tensor(0.1154)\n",
      "tensor(0.0064)\n",
      "tensor(0.0122)\n",
      "tensor(0.0768)\n",
      "tensor(0.0197)\n",
      "tensor(0.0172)\n",
      "tensor(0.0194)\n",
      "tensor(0.0232)\n",
      "tensor(0.1011)\n",
      "tensor(0.0328)\n",
      "tensor(0.0641)\n",
      "tensor(0.4357)\n",
      "tensor(0.0085)\n",
      "tensor(6.0055e-09)\n",
      "tensor(0.0496)\n",
      "tensor(0.0037)\n",
      "tensor(0.0137)\n",
      "tensor(0.0549)\n",
      "tensor(0.0143)\n",
      "tensor(0.0120)\n",
      "tensor(0.0183)\n",
      "tensor(0.0164)\n",
      "tensor(0.0526)\n",
      "tensor(0.0305)\n",
      "tensor(0.0342)\n",
      "tensor(0.0057)\n",
      "tensor(9.8749e-09)\n",
      "tensor(0.0375)\n",
      "tensor(0.0124)\n",
      "tensor(0.0346)\n",
      "tensor(0.0751)\n",
      "tensor(0.0175)\n",
      "tensor(0.0104)\n",
      "tensor(0.0339)\n",
      "tensor(0.0273)\n",
      "tensor(0.0612)\n",
      "tensor(0.0333)\n",
      "tensor(0.0342)\n",
      "tensor(0.0086)\n",
      "tensor(4.5231e-09)\n",
      "tensor(0.0344)\n",
      "tensor(0.0079)\n",
      "tensor(0.0241)\n",
      "tensor(0.0760)\n",
      "tensor(0.0153)\n",
      "tensor(0.0092)\n",
      "tensor(0.0127)\n",
      "tensor(0.0309)\n",
      "tensor(0.0685)\n",
      "tensor(0.0302)\n",
      "tensor(0.0342)\n",
      "tensor(0.0106)\n",
      "tensor(5.7727e-09)\n",
      "tensor(0.0361)\n",
      "tensor(0.0063)\n",
      "tensor(0.0122)\n",
      "tensor(0.0584)\n",
      "tensor(0.0128)\n",
      "tensor(0.0109)\n",
      "tensor(0.0237)\n",
      "tensor(0.0320)\n",
      "tensor(0.0560)\n",
      "tensor(0.0218)\n",
      "tensor(0.0342)\n",
      "tensor(0.0083)\n",
      "tensor(6.6471e-09)\n",
      "tensor(0.0328)\n",
      "tensor(0.0067)\n",
      "tensor(0.0103)\n",
      "tensor(0.0520)\n",
      "tensor(0.0142)\n",
      "tensor(0.0117)\n",
      "tensor(0.0176)\n",
      "tensor(0.0220)\n",
      "tensor(0.0476)\n",
      "tensor(0.0189)\n",
      "tensor(0.0342)\n",
      "tensor(0.0060)\n",
      "tensor(4.7982e-09)\n",
      "tensor(0.0245)\n",
      "tensor(0.0044)\n",
      "tensor(0.0101)\n",
      "tensor(0.0569)\n",
      "tensor(0.0117)\n",
      "tensor(0.0074)\n",
      "tensor(0.0124)\n",
      "tensor(0.0197)\n",
      "tensor(0.0522)\n",
      "tensor(0.0221)\n",
      "tensor(0.0342)\n",
      "tensor(0.6428)\n",
      "tensor(0.1221)\n",
      "tensor(0.1828)\n",
      "tensor(0.0061)\n",
      "tensor(0.3055)\n",
      "tensor(0.6721)\n",
      "tensor(0.0144)\n",
      "tensor(0.0455)\n",
      "tensor(0.0431)\n",
      "tensor(0.1158)\n",
      "tensor(0.0143)\n",
      "tensor(0.1665)\n",
      "tensor(0.0147)\n",
      "tensor(0.0333)\n",
      "tensor(0.0517)\n",
      "tensor(0.0020)\n",
      "tensor(0.1969)\n",
      "tensor(0.2343)\n",
      "tensor(0.0146)\n",
      "tensor(0.0393)\n",
      "tensor(0.0483)\n",
      "tensor(0.0869)\n",
      "tensor(0.0087)\n",
      "tensor(0.1101)\n",
      "tensor(0.0145)\n",
      "tensor(0.0459)\n",
      "tensor(0.0777)\n",
      "tensor(0.0017)\n",
      "tensor(0.2258)\n",
      "tensor(0.1769)\n",
      "tensor(0.0146)\n",
      "tensor(0.0652)\n",
      "tensor(0.0659)\n",
      "tensor(0.1125)\n",
      "tensor(0.0147)\n",
      "tensor(0.1077)\n",
      "tensor(0.0149)\n",
      "tensor(0.0491)\n",
      "tensor(0.0604)\n",
      "tensor(0.0026)\n",
      "tensor(0.2388)\n",
      "tensor(0.2052)\n",
      "tensor(0.0144)\n",
      "tensor(0.0288)\n",
      "tensor(0.0328)\n",
      "tensor(0.0637)\n",
      "tensor(0.0085)\n",
      "tensor(0.1018)\n",
      "tensor(0.0143)\n",
      "tensor(0.0192)\n",
      "tensor(0.0290)\n",
      "tensor(0.0015)\n",
      "tensor(0.1232)\n",
      "tensor(0.1053)\n",
      "tensor(0.0145)\n",
      "tensor(0.0127)\n",
      "tensor(0.0189)\n",
      "tensor(0.0429)\n",
      "tensor(0.0058)\n",
      "tensor(0.0775)\n",
      "tensor(0.0145)\n",
      "tensor(0.0209)\n",
      "tensor(0.0197)\n",
      "tensor(0.0014)\n",
      "tensor(0.0835)\n",
      "tensor(0.1055)\n",
      "tensor(0.0145)\n",
      "tensor(0.0215)\n",
      "tensor(0.0370)\n",
      "tensor(0.0654)\n",
      "tensor(0.0097)\n",
      "tensor(0.0749)\n",
      "tensor(0.0147)\n",
      "tensor(0.0332)\n",
      "tensor(0.0536)\n",
      "tensor(0.0012)\n",
      "tensor(0.1104)\n",
      "tensor(0.0939)\n",
      "tensor(0.0148)\n",
      "tensor(0.0779)\n",
      "tensor(0.0733)\n",
      "tensor(0.0880)\n",
      "tensor(0.0142)\n",
      "tensor(0.1168)\n",
      "tensor(0.0148)\n",
      "tensor(0.0140)\n",
      "tensor(0.0299)\n",
      "tensor(0.0007)\n",
      "tensor(0.0921)\n",
      "tensor(0.1067)\n",
      "tensor(0.0148)\n",
      "tensor(0.0321)\n",
      "tensor(0.0238)\n",
      "tensor(0.0583)\n",
      "tensor(0.0095)\n",
      "tensor(0.1014)\n",
      "tensor(0.0150)\n",
      "tensor(0.0240)\n",
      "tensor(0.0471)\n",
      "tensor(0.0007)\n",
      "tensor(0.1080)\n",
      "tensor(0.1041)\n",
      "tensor(0.0151)\n",
      "tensor(0.0146)\n",
      "tensor(0.0382)\n",
      "tensor(0.0619)\n",
      "tensor(0.0109)\n",
      "tensor(0.0759)\n",
      "tensor(0.0152)\n",
      "tensor(0.0299)\n",
      "tensor(0.0352)\n",
      "tensor(0.0011)\n",
      "tensor(0.0952)\n",
      "tensor(0.0816)\n",
      "tensor(0.0154)\n",
      "tensor(0.0297)\n",
      "tensor(0.0944)\n",
      "tensor(0.0765)\n",
      "tensor(0.0126)\n",
      "tensor(0.0860)\n",
      "tensor(0.0155)\n",
      "tensor(0.0299)\n",
      "tensor(0.0335)\n",
      "tensor(0.0006)\n",
      "tensor(0.0944)\n",
      "tensor(0.0817)\n",
      "tensor(0.0156)\n",
      "tensor(0.0432)\n",
      "tensor(0.0742)\n",
      "tensor(0.0660)\n",
      "tensor(0.0140)\n",
      "tensor(0.0656)\n",
      "tensor(0.0159)\n",
      "tensor(0.0168)\n",
      "tensor(0.0498)\n",
      "tensor(0.0008)\n",
      "tensor(0.1540)\n",
      "tensor(0.0910)\n",
      "tensor(0.0163)\n",
      "tensor(0.0396)\n",
      "tensor(0.0736)\n",
      "tensor(0.0797)\n",
      "tensor(0.0157)\n",
      "tensor(0.0880)\n",
      "tensor(0.0170)\n",
      "tensor(0.0323)\n",
      "tensor(0.0712)\n",
      "tensor(0.0012)\n",
      "tensor(0.1612)\n",
      "tensor(0.0920)\n",
      "tensor(0.0175)\n",
      "tensor(0.0789)\n",
      "tensor(0.1639)\n",
      "tensor(0.1313)\n",
      "tensor(0.0266)\n",
      "tensor(0.1003)\n",
      "tensor(0.0168)\n",
      "tensor(0.0551)\n",
      "tensor(0.0634)\n",
      "tensor(0.0008)\n",
      "tensor(0.1993)\n",
      "tensor(0.1063)\n",
      "tensor(0.0166)\n",
      "tensor(0.0928)\n",
      "tensor(0.1212)\n",
      "tensor(0.1169)\n",
      "tensor(0.0225)\n",
      "tensor(0.0811)\n",
      "tensor(0.0169)\n",
      "tensor(5.4607)\n",
      "tensor(0.0206)\n",
      "tensor(0.0551)\n",
      "tensor(0.0007)\n",
      "tensor(0.1635)\n",
      "tensor(0.1501)\n",
      "tensor(0.0210)\n",
      "tensor(0.0370)\n",
      "tensor(0.0910)\n",
      "tensor(0.1975)\n",
      "tensor(0.0198)\n",
      "tensor(0.4661)\n",
      "tensor(0.0211)\n",
      "tensor(0.0396)\n",
      "tensor(0.0772)\n",
      "tensor(0.0009)\n",
      "tensor(0.2397)\n",
      "tensor(0.2276)\n",
      "tensor(0.0216)\n",
      "tensor(0.0804)\n",
      "tensor(0.2307)\n",
      "tensor(0.2592)\n",
      "tensor(0.0291)\n",
      "tensor(0.3258)\n",
      "tensor(0.0223)\n",
      "tensor(80.6482)\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for p in model.parameters():\n",
    "    l.append(p)\n",
    "    print(p.grad.detach().data.norm(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b89f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_norm = 0\n",
    "for p in model.parameters():\n",
    "    param_norm = p.grad.data.norm(2)\n",
    "    total_norm += param_norm.item() ** 2\n",
    "total_norm = total_norm ** (1. / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015d2351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.899364188472566"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a68d0b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[306].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1e7321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0948e-01,  1.2206e-01, -5.8916e-02,  9.5959e-02, -2.1617e-02,\n",
       "         -1.0522e-01,  3.7879e-01, -8.3562e-02, -1.5823e-01,  6.7311e-02,\n",
       "         -2.0929e-02, -4.9176e-02, -1.9714e-01,  7.3419e-02,  2.2830e-01,\n",
       "         -8.8453e-02,  5.6505e-02, -1.3219e-01, -1.4008e-01,  2.8202e-01,\n",
       "         -1.5654e-02,  2.3450e-01,  2.3076e-01, -2.0737e-01, -3.3124e-01,\n",
       "         -1.8739e-02,  3.7286e-03,  1.9267e-01, -8.1636e-02, -1.6118e-01,\n",
       "          1.0336e-01,  1.7612e-01,  3.2468e-02, -1.9655e-01,  5.1311e-03,\n",
       "         -1.3259e-01, -2.4123e-01,  8.8786e-03,  5.1155e-01,  1.2136e-01,\n",
       "          1.5619e-02, -3.6234e-02,  3.2968e-02,  2.9989e-02, -3.1859e-01,\n",
       "         -2.2635e-02, -1.8895e-01, -6.4662e-02, -2.6324e-01, -1.6741e-01,\n",
       "         -2.7958e-01,  5.7902e-03, -2.0965e-01, -3.1295e-03, -1.1830e-01,\n",
       "          1.8381e-01,  9.5175e-02,  1.4199e-01,  1.2826e-02, -5.9812e-02,\n",
       "         -9.9080e-03,  1.0078e-01,  1.4549e-02,  2.0667e-01, -1.0222e-02,\n",
       "          2.1716e-01,  9.3591e-02, -1.8128e-01,  1.3550e-01,  3.9392e-02,\n",
       "          6.5916e-02, -3.6063e-02, -1.2641e-01,  9.2424e-02, -2.3204e-01,\n",
       "         -1.8417e-01, -2.0706e-01,  6.8164e-02,  8.0705e-03, -5.1833e-02,\n",
       "          1.7788e-01, -1.4467e-01,  1.7296e-01, -2.9305e-01,  4.7367e-02,\n",
       "         -1.2129e-01,  2.6326e-02, -1.0122e-01,  7.2416e-02,  1.5689e-01,\n",
       "          1.6815e-01,  7.1767e-02, -1.5087e-01,  9.9841e-02, -5.4320e-02,\n",
       "          1.1242e-01,  1.9861e-02,  6.7844e-02,  2.1612e-01,  9.3807e-02,\n",
       "         -4.7760e-02,  1.3793e-01,  2.3269e-01, -1.2642e-01,  2.1321e-01,\n",
       "          1.0397e-01, -1.0854e-01,  2.5143e-01, -6.8485e-02, -1.3719e-01,\n",
       "          3.4814e-02, -1.8935e-02, -9.8552e-02,  1.1936e-01, -4.1389e-01,\n",
       "         -4.1801e-01,  5.4619e-02,  1.3477e-02, -6.4135e-02,  1.5863e-01,\n",
       "          7.1599e-02, -1.7854e-01, -2.2706e-01, -3.2986e-02,  7.9888e-02,\n",
       "          5.1017e-02, -1.3950e-01, -9.9872e-03, -1.8329e-01,  2.9149e-01,\n",
       "          5.6793e-02,  3.1948e-02,  2.5268e-01,  1.5376e-01,  1.2154e-01,\n",
       "         -1.2376e-01, -9.9144e-03,  3.1781e-01,  1.8049e-01,  1.3561e-01,\n",
       "         -1.4220e-01, -1.0009e-01, -4.7801e-01, -7.3486e-02,  3.7480e-01,\n",
       "          2.8058e-01, -1.8449e-01, -9.4027e-02, -1.8610e-01,  2.6957e-01,\n",
       "          2.1042e-02, -7.9741e-02, -2.6285e-02,  1.3192e-01, -1.2420e-01,\n",
       "          1.3227e-01,  2.0151e-01, -2.9594e-02,  1.0267e-01,  1.6014e-01,\n",
       "          2.0553e-01, -1.4051e-01, -3.7797e-02, -3.7150e-01, -1.6021e-02,\n",
       "         -1.9415e-01, -3.9294e-02, -4.2739e-01,  2.5999e-01,  2.1472e-01,\n",
       "          2.0530e-01, -1.0511e-01, -4.7838e-01, -1.6060e-01, -9.5079e-02,\n",
       "          1.0329e-01, -1.9356e-01, -7.0365e-02, -4.7297e-02,  3.5925e-02,\n",
       "          5.9578e-02,  1.1916e-01,  4.5066e-02, -7.8065e-02, -2.5193e-01,\n",
       "          4.1262e-02, -1.2780e-01, -3.0245e-01,  8.9752e-02,  1.3285e-01,\n",
       "          1.9234e-01, -1.3925e-01, -1.8042e-01,  1.9226e-01, -1.7827e-01,\n",
       "          1.4010e-01, -9.9609e-02, -4.3207e-01, -1.4786e-01, -1.8653e-01,\n",
       "         -3.6644e-01,  5.5814e-02, -1.5567e-01, -6.3480e-02, -6.5564e-02,\n",
       "         -1.6918e-01,  3.9184e-02, -1.8323e-01, -2.2670e-01,  3.1297e-01,\n",
       "          3.9798e-02,  1.0081e-01,  8.8521e-02,  2.7492e-01,  3.3965e-01,\n",
       "         -3.4788e-02,  1.5356e-02, -1.6007e-01, -2.8889e-01,  2.6735e-04,\n",
       "         -3.6518e-01, -1.7057e-01, -9.5419e-02,  3.4343e-02,  7.8662e-02,\n",
       "         -1.1107e-01, -7.9932e-02,  1.0083e-01,  7.1024e-02, -3.9386e-01,\n",
       "         -1.7289e-01, -1.2889e-01, -7.7392e-02, -1.8485e-01,  1.8194e-01,\n",
       "          7.6975e-02,  1.7877e-01, -2.0228e-01, -5.1717e-02, -1.1091e-01,\n",
       "         -1.4262e-01,  1.4983e-01, -7.6790e-02, -5.3070e-02,  5.6772e-02,\n",
       "         -5.5557e-02,  1.7620e-02,  2.5154e-02,  2.4104e-01, -1.0238e-01,\n",
       "         -1.4268e-02, -1.2524e-01, -3.7501e-02,  4.4371e-02,  7.0566e-02,\n",
       "          3.5434e-01, -1.2192e-01,  1.3038e-01, -8.0547e-02, -1.7704e-02,\n",
       "         -2.1255e-01,  2.2772e-01,  1.9307e-01, -9.1490e-02, -1.1845e-01,\n",
       "         -1.4735e-02, -2.2611e-01, -1.0497e-01, -1.2435e-01, -2.3343e-01,\n",
       "          3.2531e-01, -4.2760e-02, -8.5700e-02, -1.2485e-01, -6.5406e-02,\n",
       "          1.4294e-01,  4.7068e-02,  3.2602e-01,  2.1294e-01,  4.7287e-01,\n",
       "          7.8181e-02,  3.2952e-01, -3.8531e-01, -5.5019e-01, -4.4206e-01,\n",
       "          2.4322e-02,  1.2964e-02,  8.9866e-02, -8.3675e-02,  6.0530e-03,\n",
       "          8.5481e-02, -1.5794e-01,  6.1850e-02, -1.0524e-01,  1.0880e-01,\n",
       "          2.5295e-03, -1.7738e-01,  2.4801e-01,  9.6693e-02, -2.0105e-01,\n",
       "          1.2762e-01, -1.7561e-01, -2.9717e-02,  8.1238e-02,  4.3549e-01,\n",
       "         -1.3275e-01,  1.2935e-01,  1.8761e-02, -1.0225e-01,  2.5151e-02,\n",
       "         -1.3261e-01,  9.1441e-02,  5.5712e-02, -1.6503e-01,  8.0103e-03,\n",
       "         -3.6578e-01, -1.4725e-01, -9.6805e-02,  1.5549e-01, -3.7008e-02,\n",
       "         -6.0771e-02,  9.8049e-02,  3.3224e-01, -1.7059e-01, -3.0138e-01,\n",
       "          8.4424e-02, -1.7858e-02,  9.2144e-02, -2.4760e-01,  1.9073e-01,\n",
       "          1.8300e-01, -1.5208e-01,  2.1998e-02,  1.9787e-02, -3.8427e-03,\n",
       "          1.5091e-01, -2.2254e-01,  2.4061e-01,  2.1722e-01, -7.4574e-03,\n",
       "         -1.0191e-01,  2.5092e-01, -8.0407e-02,  6.2939e-02,  4.7973e-02,\n",
       "          3.2925e-01, -1.8755e-01, -1.2105e-01,  2.4429e-01,  1.1198e-01,\n",
       "         -2.1034e-01,  3.0638e-01, -3.5104e-01,  1.8355e-01, -2.3576e-01,\n",
       "          1.5190e-01,  2.4681e-01, -2.4104e-01, -1.7957e-02,  6.3161e-02,\n",
       "         -1.8037e-01, -7.1681e-02, -3.5128e-02, -1.9323e-01,  2.6698e-01,\n",
       "         -4.9722e-02,  1.9705e-01,  2.9075e-01,  1.6924e-01, -3.9144e-02,\n",
       "          1.0336e-01,  1.0536e-01, -2.1456e-01, -2.8638e-01, -3.0701e-02,\n",
       "          1.4047e-03, -5.2183e-01,  2.0677e-01,  6.0455e-02,  2.4078e-02,\n",
       "          2.8108e-02, -9.9213e-02, -1.3891e-01, -3.7690e-02,  1.6955e-01,\n",
       "         -6.5638e-02,  3.3980e-01,  6.6045e-02,  1.5330e-02, -6.3886e-02,\n",
       "          1.4505e-01,  7.8247e-02, -9.2176e-02, -1.3072e-01, -1.8430e-01,\n",
       "          1.4379e-01,  1.5946e-01,  2.2701e-01, -7.8740e-02, -5.8087e-02,\n",
       "          2.2551e-02,  2.2290e-01,  7.6544e-02,  1.6905e-02,  1.7649e-01,\n",
       "         -1.9838e-01,  1.0112e-01,  2.5660e-01,  1.8142e-01,  6.2342e-02,\n",
       "          1.3221e-01, -6.3247e-02, -1.5384e-01,  1.9700e-01, -3.7317e-04,\n",
       "          1.3422e-01, -2.1096e-01,  3.4363e-01, -1.4673e-02,  2.7711e-01,\n",
       "         -9.3796e-02, -1.1865e-02, -3.2580e-01, -1.0454e-01, -7.3790e-02,\n",
       "         -4.0005e-03, -2.6048e-01, -7.5805e-02,  6.2413e-02,  1.0287e-01,\n",
       "          2.2426e-02,  2.1334e-01, -5.7484e-01,  4.1736e-02, -5.8716e-02,\n",
       "         -1.1358e-01,  1.2940e-02,  3.0066e-01, -1.2826e-01, -1.4240e-01,\n",
       "         -8.6225e-02,  2.5612e-01, -3.1630e-01, -1.2539e-01, -1.7751e-01,\n",
       "          1.1833e-01,  3.5854e-01,  2.7240e-01,  2.2862e-01,  2.0656e-01,\n",
       "         -3.6840e-01,  6.4414e-02,  1.2339e-01, -2.1408e-01, -1.2385e-01,\n",
       "         -1.3741e-02,  1.6016e-01,  1.7272e-01, -1.6813e-01,  3.6383e-02,\n",
       "         -9.3478e-02,  2.7236e-03, -9.3788e-02,  6.3156e-03, -2.2781e-01,\n",
       "          2.2803e-01,  2.2418e-01, -9.0908e-02, -1.2901e-01, -6.0869e-02,\n",
       "          7.7296e-02,  3.6359e-02, -1.4512e-01,  1.1909e-01, -2.3074e-01,\n",
       "          1.1873e-01, -2.0924e-01,  1.5397e-01, -1.2881e-02,  4.0260e-02,\n",
       "          2.0263e-01,  2.8353e-02, -8.3069e-02, -2.6867e-01, -5.1023e-02,\n",
       "         -7.3344e-02, -1.4790e-01, -1.6122e-01, -1.3050e-01, -1.4641e-01,\n",
       "         -9.6201e-02, -2.3500e-01,  9.9414e-02, -2.1550e-01, -1.7131e-01,\n",
       "         -2.9075e-01, -1.1083e-01,  1.3767e-01,  3.1606e-01, -1.1609e-01,\n",
       "          6.2918e-02, -2.2133e-01, -1.5661e-01,  1.8629e-01, -7.9213e-02,\n",
       "          8.1818e-02, -1.4971e-01, -6.0890e-02, -7.5413e-02,  1.3475e-02,\n",
       "          4.4026e-02, -1.4036e-01,  1.1090e-01, -2.6877e-01, -5.3677e-02,\n",
       "          1.4858e-01,  7.6858e-02, -1.8903e-01,  3.5688e-01, -2.3485e-01,\n",
       "          2.1951e-01, -1.6608e-01, -1.6502e-01, -7.9989e-02,  9.8891e-02,\n",
       "         -3.4455e-02, -9.5178e-02, -1.4226e-01, -1.7050e-01, -5.6838e-02,\n",
       "          6.6476e-02,  3.7567e-01, -2.5795e-01,  5.2132e-02, -3.1019e-01,\n",
       "         -2.6769e-01,  1.3599e-01, -1.2421e-01, -7.2896e-03, -8.2793e-01,\n",
       "         -2.3261e-01, -1.0371e-03, -9.2827e-02, -8.5406e-02, -1.5527e-01,\n",
       "         -1.7719e-01,  6.6693e-02,  1.2982e-01, -2.4457e-01,  5.4732e-02,\n",
       "          7.7862e-02, -9.1476e-03, -5.9246e-01, -2.8271e-03, -9.0407e-02,\n",
       "         -2.4425e-01, -7.8039e-02,  1.9380e-03, -1.2831e-01,  7.7755e-02,\n",
       "          3.3113e-01, -2.9011e-02,  1.5638e-01, -2.0440e-02, -6.5967e-02,\n",
       "         -1.7277e-01,  1.2534e-01, -8.7480e-02, -1.1938e-01, -3.6869e-02,\n",
       "          2.0958e-01, -3.4009e-01, -1.3854e-01,  2.6777e-01,  1.8935e-01,\n",
       "         -7.4565e-02, -4.5359e-02,  2.3095e-01, -5.3429e-02,  7.9521e-02,\n",
       "         -2.6708e-01,  3.1957e-02,  3.9805e-02, -1.0562e-01, -2.4412e-01,\n",
       "         -2.9926e-02,  1.4726e-01,  5.3354e-02,  2.9492e-01, -4.5436e-01,\n",
       "         -1.4992e-02, -1.7154e-01, -2.1152e-01, -6.7797e-02,  5.1774e-01,\n",
       "         -6.9234e-01, -2.4713e-01,  2.0498e-01, -3.2341e-01, -2.9324e-01,\n",
       "          1.9828e-01,  6.9176e-02,  2.2997e-01,  3.7686e-02, -4.3566e-02,\n",
       "         -2.9012e-02,  2.5678e-01,  5.9084e-02,  2.6089e-01, -1.7253e-01,\n",
       "         -1.3064e-01,  1.3937e-01, -2.1541e-01,  2.0543e-01, -2.7017e-01,\n",
       "          3.2478e-01,  2.4735e-01,  1.1067e-01,  6.7472e-02, -1.1906e-01,\n",
       "         -1.7764e-01,  1.0729e-02,  4.3018e-02,  2.7171e-02,  3.1397e-02,\n",
       "          1.2002e-01, -9.2932e-02, -5.5642e-02,  2.5317e-01, -8.4705e-02,\n",
       "          1.1111e-01, -4.8102e-02,  4.2968e-03, -8.1134e-02, -1.0019e-02,\n",
       "         -1.5486e-01,  2.1343e-01, -1.3577e-01, -1.8705e-01, -2.1679e-01,\n",
       "         -3.9516e-02,  5.3537e-02, -2.9888e-02, -1.7886e-01, -2.7055e-01,\n",
       "          4.8758e-02, -7.0338e-02, -1.7051e-02,  1.5822e-01, -5.0380e-02,\n",
       "          3.1771e-01,  2.8253e-01, -5.2121e-02, -6.6836e-02, -1.7787e-02,\n",
       "         -1.3524e-01, -6.7932e-02, -1.4231e-01,  2.3932e-01, -2.8308e-01,\n",
       "          2.6175e-01, -1.5055e-02, -3.6863e-02, -1.3525e-01, -4.6240e-03,\n",
       "          2.9083e-01, -1.0468e-01, -1.7991e-01, -8.5375e-02, -4.0799e-02,\n",
       "          2.6444e-01,  3.0205e-01, -3.8479e-02,  7.7707e-02,  1.2017e-02,\n",
       "         -4.2181e-02, -1.1567e-01,  1.7115e-01,  1.7068e-01,  3.3062e-02,\n",
       "          4.4038e-01,  2.2108e-01,  2.8025e-01,  1.5985e-01,  3.1158e-01,\n",
       "         -2.3061e-01, -6.1141e-02,  6.5379e-02,  4.7292e-02,  3.0063e-03,\n",
       "          1.8359e-01,  6.9386e-02,  1.1102e-01,  1.0171e-01, -1.8169e-01,\n",
       "          1.3488e-01, -1.9456e-01, -1.6074e-01, -2.2018e-01, -3.6912e-01,\n",
       "         -5.2269e-02, -2.9998e-01, -1.3436e-01,  6.2393e-02,  3.9902e-01,\n",
       "         -1.9832e-01,  4.9927e-02,  8.9049e-02, -9.6462e-02,  2.9859e-01,\n",
       "          1.2255e-01,  2.4069e-01, -3.1550e-02, -4.5845e-01,  9.6130e-02,\n",
       "          9.1263e-02, -1.6704e-02,  3.8276e-02,  1.1958e-01, -3.5828e-02,\n",
       "         -1.4812e-01,  4.5124e-02,  5.4594e-02,  2.3657e-01,  1.0576e-01,\n",
       "         -2.0585e-01,  4.3047e-03, -1.0527e-02, -7.0935e-03,  2.7635e-02,\n",
       "          5.1433e-02, -1.1696e-02,  5.3720e-02, -5.4969e-04,  1.0762e-01,\n",
       "         -2.6368e-02,  2.7198e-01, -6.2537e-02,  1.8826e-01, -7.1963e-02,\n",
       "         -9.3671e-02,  5.5645e-02,  2.2816e-01, -2.0062e-02, -1.5326e-01,\n",
       "         -2.6700e-01,  8.9478e-02,  1.4544e-01, -5.8842e-02,  1.1689e-01,\n",
       "          1.1632e-01, -2.4313e-01, -9.0384e-02, -6.4066e-02, -3.9578e-02,\n",
       "          2.2441e-01, -1.8338e-01, -1.3669e-01, -2.7487e-01, -2.9354e-01,\n",
       "          4.6890e-02, -1.3111e-01, -2.5359e-01, -2.6438e-01, -5.2414e-02,\n",
       "          1.0899e-01,  3.5420e-02, -4.8338e-01]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[-1].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8b47f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6339, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90c52aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0009)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([-7.0])\n",
    "b = torch.tensor([0])\n",
    "nn.BCEWithLogitsLoss()(a,b.float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
