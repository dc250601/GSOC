{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import gc \n",
    "#Stage 1> A clean Swin transformer model will be trained trained\n",
    "#Stage 2> The swin Transformer blocks are frozen and the new embeding layer is attached and trained\n",
    "#The old embedding blocks are replaced by the CNNs.In this stage only the embeding layer is trained\n",
    "#Stage 3> The entire model is unfrozen and trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return auc\n",
    "\n",
    "def straightner(a):\n",
    "    A = np.zeros((a[0].shape[0]*len(a)))\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    for i in range(len(a)):\n",
    "        start_index = i*a[0].shape[0]\n",
    "        end_index = start_index+a[0].shape[0]\n",
    "        A[start_index:end_index] = a[i]\n",
    "    return A\n",
    "\n",
    "def predictor(outputs):\n",
    "    return np.argmax(outputs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid_embed(nn.Module):\n",
    "    def __init__(self, feature_model, img_size, channels, efn_blocks, dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.feature_extractor = timm.create_model(feature_model,\n",
    "                                                   features_only=True,\n",
    "                                                   out_indices=[efn_blocks])\n",
    "        \n",
    "        \n",
    "        self.feature_extractor.conv_stem = nn.Conv2d(3,   \n",
    "                                       40,\n",
    "                                       kernel_size=(3, 3),\n",
    "                                       stride=(4, 4),\n",
    "                                       padding=(1, 1),\n",
    "                                       bias=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "                # NOTE Most reliable way of determining output dims is to run forward pass\n",
    "                training = self.feature_extractor.training\n",
    "                if training:\n",
    "                    self.feature_extractor.eval()\n",
    "                o = self.feature_extractor(torch.zeros(1, channels, img_size[0], img_size[1]))\n",
    "                self.channel_output = o[0].shape[1]\n",
    "                self.feature_extractor.train(training)\n",
    "        \n",
    "        self.embed_matcher = nn.Sequential(\n",
    "            nn.Conv2d(self.channel_output, dims, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(dims, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            x = x[-1]  # last feature if backbone outputs list/tuple of features\n",
    "        x = self.embed_matcher(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid_swin_effnet(nn.Module):\n",
    "    def __init__(self, feature_model = \"efficientnet_b3\",img_size = (224,224), channels = 3, efn_blocks = 2, swin_blocks = 2, no_classes = 1):\n",
    "        super().__init__()\n",
    "        assert efn_blocks + swin_blocks == 4,f\"The total no of blocks must be 4, instead {efn_blocks+swin_blocks} blocks provided \"\n",
    "        self.s1_flag = True\n",
    "        self.s2_flag = True\n",
    "        self.s3_flag = True\n",
    "        self.swin_blocks = swin_blocks\n",
    "#         self.feature_extractor = timm.create_model(feature_model,\n",
    "#                                                    features_only=True,\n",
    "#                                                    out_indices=[efn_blocks])\n",
    "        \n",
    "#         #Removing the initial stem layer since our image size is pretty low and we have already upscaled it.\n",
    "#         self.feature_extractor.conv_stem = nn.Conv2d(3,   \n",
    "#                                        40,\n",
    "#                                        kernel_size=(3, 3),\n",
    "#                                        stride=(4, 4),\n",
    "#                                        padding=(1, 1),\n",
    "#                                        bias=False)\n",
    "        \n",
    "#         #------------------------------------------------------------------\n",
    "#         with torch.no_grad():\n",
    "#                 # NOTE Most reliable way of determining output dims is to run forward pass\n",
    "#                 training = self.feature_extractor.training\n",
    "#                 if training:\n",
    "#                     self.feature_extractor.eval()\n",
    "#                 o = self.feature_extractor(torch.zeros(1, channels, img_size[0], img_size[1]))\n",
    "#                 self.channel_output = o[0].shape[1]\n",
    "#                 self.feature_extractor.train(training)\n",
    "        \n",
    "#         #------------------------------------------------------------------\n",
    "        self.swin_backbone = timm.create_model(\"swin_tiny_patch4_window7_224\")\n",
    "        \n",
    "#         self.original_embed = self.swin_backbone.patch_embed\n",
    "        \n",
    "        self.embeded_dim = self.swin_backbone.embed_dim * (2**(4 - self.swin_blocks))\n",
    "        \n",
    "#         self.embed_matcher = nn.Sequential(\n",
    "#             nn.Conv2d(self.channel_output, self.embeded_dim, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "#             nn.BatchNorm2d(self.embeded_dim, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "#             nn.SiLU(inplace=True)\n",
    "#         )\n",
    "        \n",
    "#         #Matching the output channel\n",
    "#         self.patc_embed_hybrid = nn.Sequential(self.feature_extractor, self.embed_matcher)\n",
    "#         # !!!!!!!! The [0] should be inspected !!!!!\n",
    "        \n",
    "#         self.swin_backbone.patch_embed = self.patc_embed_hybrid\n",
    "\n",
    "\n",
    "        self.Hybrid_patch_embed = Hybrid_embed(feature_model = \"efficientnet_b3\",\n",
    "                                                      img_size = (224,224),\n",
    "                                                      channels = 3,\n",
    "                                                      efn_blocks = 2, \n",
    "                                                      dims = self.embeded_dim)\n",
    "        \n",
    "        #setting the first few blocks of swin to Indentity to match size\n",
    "#         for i in range((4- swin_blocks)):\n",
    "#             self.swin_backbone.layers[i] = nn.Identity()\n",
    "        \n",
    "        #Setting the head as per our need\n",
    "        self.swin_backbone.head = nn.Linear(self.swin_backbone.num_features, no_classes)\n",
    "        \n",
    "    def forward(self, image, stage):\n",
    "        \n",
    "        \n",
    "        if stage == 2:\n",
    "            #Attaching the new embeding layer\n",
    "                \n",
    "            self.swin_backbone.patch_embed = self.Hybrid_patch_embed\n",
    "\n",
    "            for i in range((4- self.swin_blocks)):\n",
    "                self.swin_backbone.layers[i] = nn.Identity()\n",
    "\n",
    "            #Freezing the swin layers    \n",
    "            for layer in self.swin_backbone.layers:\n",
    "                for para in layer.parameters():\n",
    "                    para.requires_grad = False\n",
    "\n",
    "           #Freezing the head    \n",
    "            for para in self.swin_backbone.head.parameters():\n",
    "                    para.requires_grad = False\n",
    "            \n",
    "        if stage == 3:\n",
    "            #Unfreezing the network\n",
    "            for para in self.swin_backbone.parameters():\n",
    "                para.requires_grad = True\n",
    "    \n",
    "                \n",
    "        return self.swin_backbone(image).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e59306",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Rules of the game-\n",
    "-----------------------------------\n",
    "Stage 1: Nothing has to be done and a value of 1 has to be passed to the stage parameter.\n",
    "The model has to be trained for 50 epochs as warmup.\n",
    "With initial LR OF 0.0001 along with lr-on-pleatue scheduler with patience 3 and factor 0.5\n",
    "\n",
    "Stage 2: The first batch has to be passed with the stage parameter as 2 and for the next batches\n",
    "the stage parameter will be kept to 1. The model will be trained with a learning rate of 0.001 which\n",
    "will be gradually reduced with a lr-on-pleatue scheduler with patience 3 and factor 0.5. The model\n",
    "will be trained in this stage for 20 epochs.\n",
    "\n",
    "Stage 3: The first batch has to be passed with the stage parameter as 2 and for the next batches\n",
    "the stage parameter will be kept to 1.The model will be trained with a learning rate of 0.00001 which\n",
    "will be gradually reduced with a lr-on-pleatue scheduler with patience 5 and factor 0.7. The model\n",
    "will be trained in this phase for some 150 epochs\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd866247",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.RandomVerticalFlip(),\n",
    "                            transforms.RandomRotation(20),\n",
    "                            transforms.ToTensor()\n",
    "                           ])\n",
    "test_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                            transforms.ToTensor()\n",
    "                           ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = Hybrid_swin_effnet()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"cb53927c12bd57a0d943d2dedf7881cfcdcc8f09\")\n",
    "wandb.init(\n",
    "    project = \"Hybrid_Zoo\",\n",
    "    name = \"Eff2_Swin_trained_step_by_step_rtc\"\n",
    ")\n",
    "\n",
    "sample = torch.randn(1, 3, 224, 224, device = \"cuda\")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "#--------------------------\n",
    "wandb.watch(model, log_freq=50)\n",
    "#---------------------------\n",
    "w_intr = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_Train = datasets.ImageFolder('./Quark_Gluon_Mini/Train/', transform=train_transform)\n",
    "dataset_Test = datasets.ImageFolder('./Quark_Gluon_Mini/Test/', transform =test_transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_Train, batch_size=128, shuffle=True, drop_last = True, num_workers=0, pin_memory = True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_Test, batch_size=128, shuffle=True, drop_last = True, num_workers=0, pin_memory = True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 -----------------------------------------------------------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0001, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', verbose = True,threshold = 0.001,patience = 3, factor = 0.5)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    test_steps = 0\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    train_auc = 0\n",
    "    test_auc = 0\n",
    "    model.train()\n",
    "    for image, label in tqdm(dataloader_train):\n",
    "        image = image.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        #optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "          outputs = model(image ,1)\n",
    "          loss = criterion(outputs, label.float())\n",
    "        label_list.append(label.detach().cpu().numpy())\n",
    "        outputs_list.append(outputs.detach().cpu().numpy())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        if train_steps%w_intr == 0:\n",
    "             wandb.log({\"loss\": loss.item()})\n",
    "    with torch.no_grad():\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        train_auc = metric(label_list, outputs_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(dataloader_test):\n",
    "            image = image.to(\"cuda\")\n",
    "            label = label.to(\"cuda\")\n",
    "            outputs = model(image ,1)\n",
    "            loss = criterion(outputs, label.float())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            val_loss += loss.item()\n",
    "            test_steps +=1\n",
    "            if test_steps%w_intr == 0:\n",
    "             wandb.log({\"val_loss\": loss.item()})\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        test_auc = metric(label_list, outputs_list)\n",
    "\n",
    "    train_loss = train_loss/train_steps\n",
    "    val_loss = val_loss/ test_steps\n",
    "\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Epoch No\" , epoch)\n",
    "    print(\"The Training loss of the epoch, \",train_loss)\n",
    "    print(\"The Training AUC of the epoch,  %.3f\"%train_auc)\n",
    "    print(\"The validation loss of the epoch, \",val_loss)\n",
    "    print(\"The validation AUC of the epoch, %.3f\"%test_auc)\n",
    "    print(\"----------------------------------------------------\")\n",
    "#     PATH = \"model.pt\"\n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'scheduler': scheduler.state_dict()\n",
    "#             }, PATH)\n",
    "    scheduler.step(test_auc)\n",
    "    curr_lr = scheduler._last_lr[0]\n",
    "    wandb.log({\"Train_auc_epoch\": train_auc,\n",
    "              \"Epoch\": epoch,\n",
    "              \"Val_auc_epoch\": test_auc,\n",
    "              \"Train_loss_epoch\": train_loss,\n",
    "              \"Val_loss_epoch\": val_loss,\n",
    "              \"Lr\": curr_lr, \n",
    "              \"Stage\": 1\n",
    "              }\n",
    "             )\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_Train = datasets.ImageFolder('./Quark_Gluon_Mini/Train/', transform=train_transform)\n",
    "dataset_Test = datasets.ImageFolder('./Quark_Gluon_Mini/Test/', transform =test_transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_Train, batch_size=256, shuffle=True, drop_last = True, num_workers=0, pin_memory = True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_Test, batch_size=256, shuffle=True, drop_last = True, num_workers=0, pin_memory = True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b177644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2--------------------------------------------------------------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', verbose = True,threshold = 0.001,patience = 3, factor = 0.5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(sample,2)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    test_steps = 0\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    train_auc = 0\n",
    "    test_auc = 0\n",
    "    model.train()\n",
    "    for image, label in tqdm(dataloader_train):\n",
    "        image = image.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        #optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "          outputs = model(image ,1)\n",
    "          loss = criterion(outputs, label.float())\n",
    "        label_list.append(label.detach().cpu().numpy())\n",
    "        outputs_list.append(outputs.detach().cpu().numpy())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        if train_steps%w_intr == 0:\n",
    "             wandb.log({\"loss\": loss.item()})\n",
    "    with torch.no_grad():\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        train_auc = metric(label_list, outputs_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(dataloader_test):\n",
    "            image = image.to(\"cuda\")\n",
    "            label = label.to(\"cuda\")\n",
    "            outputs = model(image, 1)\n",
    "            loss = criterion(outputs, label.float())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            val_loss += loss.item()\n",
    "            test_steps +=1\n",
    "            if test_steps%w_intr == 0:\n",
    "             wandb.log({\"val_loss\": loss.item()})\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        test_auc = metric(label_list, outputs_list)\n",
    "\n",
    "    train_loss = train_loss/train_steps\n",
    "    val_loss = val_loss/ test_steps\n",
    "\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Epoch No\" , epoch)\n",
    "    print(\"The Training loss of the epoch, \",train_loss)\n",
    "    print(\"The Training AUC of the epoch,  %.3f\"%train_auc)\n",
    "    print(\"The validation loss of the epoch, \",val_loss)\n",
    "    print(\"The validation AUC of the epoch, %.3f\"%test_auc)\n",
    "    print(\"----------------------------------------------------\")\n",
    "#     PATH = \"model.pt\"\n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'scheduler': scheduler.state_dict()\n",
    "#             }, PATH)\n",
    "    scheduler.step(test_auc)\n",
    "    curr_lr = scheduler._last_lr[0]\n",
    "    wandb.log({\"Train_auc_epoch\": train_auc,\n",
    "              \"Epoch\": epoch,\n",
    "              \"Val_auc_epoch\": test_auc,\n",
    "              \"Train_loss_epoch\": train_loss,\n",
    "              \"Val_loss_epoch\": val_loss,\n",
    "              \"Lr\": curr_lr, \n",
    "              \"Stage\": 2\n",
    "              }\n",
    "             )\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52025289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3--------------------------------------------------------------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0001, weight_decay=0.05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', verbose = True,threshold = 0.001,patience = 5, factor = 0.7)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(sample,3)\n",
    "\n",
    "for epoch in range(150):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    test_steps = 0\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    train_auc = 0\n",
    "    test_auc = 0\n",
    "    model.train()\n",
    "    for image, label in tqdm(dataloader_train):\n",
    "        image = image.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        #optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "          outputs = model(image ,1)\n",
    "          loss = criterion(outputs, label.float())\n",
    "        label_list.append(label.detach().cpu().numpy())\n",
    "        outputs_list.append(outputs.detach().cpu().numpy())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        if train_steps%w_intr == 0:\n",
    "             wandb.log({\"loss\": loss.item()})\n",
    "    with torch.no_grad():\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        train_auc = metric(label_list, outputs_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(dataloader_test):\n",
    "            image = image.to(\"cuda\")\n",
    "            label = label.to(\"cuda\")\n",
    "            outputs = model(image,1)\n",
    "            loss = criterion(outputs, label.float())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            val_loss += loss.item()\n",
    "            test_steps +=1\n",
    "            if test_steps%w_intr == 0:\n",
    "             wandb.log({\"val_loss\": loss.item()})\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        test_auc = metric(label_list, outputs_list)\n",
    "\n",
    "    train_loss = train_loss/train_steps\n",
    "    val_loss = val_loss/ test_steps\n",
    "\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Epoch No\" , epoch)\n",
    "    print(\"The Training loss of the epoch, \",train_loss)\n",
    "    print(\"The Training AUC of the epoch,  %.3f\"%train_auc)\n",
    "    print(\"The validation loss of the epoch, \",val_loss)\n",
    "    print(\"The validation AUC of the epoch, %.3f\"%test_auc)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    PATH = f\"model_epoch_{epoch}_stage_3.pt\"\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "            }, PATH)\n",
    "    scheduler.step(test_auc)\n",
    "    curr_lr = scheduler._last_lr[0]\n",
    "    wandb.log({\"Train_auc_epoch\": train_auc,\n",
    "              \"Epoch\": epoch,\n",
    "              \"Val_auc_epoch\": test_auc,\n",
    "              \"Train_loss_epoch\": train_loss,\n",
    "              \"Val_loss_epoch\": val_loss,\n",
    "              \"Lr\": curr_lr, \n",
    "              \"Stage\": 3\n",
    "              }\n",
    "             )\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
