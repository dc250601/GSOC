{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf99ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8884bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.downsample = out_channels//in_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=self.downsample, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=self.downsample)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample > 1:\n",
    "            residual = self.shortcut(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, nblocks, fmaps):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.fmaps = fmaps\n",
    "        self.nblocks = nblocks\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels, fmaps[0], kernel_size=7, stride=2, padding=1)\n",
    "        self.layer1 = self.block_layers(self.nblocks, [fmaps[0],fmaps[0]])\n",
    "        self.layer2 = self.block_layers(1, [fmaps[0],fmaps[1]])\n",
    "        self.layer3 = self.block_layers(self.nblocks, [fmaps[1],fmaps[1]])\n",
    "        self.fc = nn.Linear(fmaps[1], 1)\n",
    "        #self.FCN = nn.Sequential(\n",
    "        #        nn.Linear(fmaps[1], 128), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        #        nn.Linear(128, 128), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        #        nn.Linear(128, 128), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        #        nn.Linear(128, 3)\n",
    "        #        )\n",
    "        \n",
    "    def block_layers(self, nblocks, fmaps):\n",
    "        layers = []\n",
    "        for _ in range(nblocks):\n",
    "            layers.append(ResBlock(fmaps[0], fmaps[1]))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "        x = x.view(x.size()[0], self.fmaps[1])\n",
    "        x = self.fc(x)\n",
    "        #x = self.FCN(x)\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a323799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return auc\n",
    "\n",
    "def straightner(a):\n",
    "    A = np.zeros((a[0].shape[0]*len(a)))\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    for i in range(len(a)):\n",
    "        start_index = i*a[0].shape[0]\n",
    "        end_index = start_index+a[0].shape[0]\n",
    "        A[start_index:end_index] = a[i]\n",
    "    return A\n",
    "\n",
    "def predictor(outputs):\n",
    "    return np.argmax(outputs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1017315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coat():\n",
    "    model = ResNet(3, 3, [16, 32])\n",
    "    \n",
    "    train_transform = transforms.Compose([transforms.Resize((125,125)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.RandomRotation(20),\n",
    "                                transforms.ToTensor()\n",
    "                               ])\n",
    "    test_transform = transforms.Compose([transforms.Resize((125,125)),\n",
    "                                transforms.ToTensor()\n",
    "                               ])\n",
    "    \n",
    "    \n",
    "    dataset_Train = datasets.ImageFolder('./Quark_Gluon_Mini/Train/', transform=train_transform)\n",
    "    dataset_Test = datasets.ImageFolder('./Quark_Gluon_Mini/Test/', transform =test_transform)\n",
    "    dataloader_train = torch.utils.data.DataLoader(dataset_Train, batch_size=3072, shuffle=True, drop_last = True, num_workers=4, pin_memory = False)\n",
    "    dataloader_test = torch.utils.data.DataLoader(dataset_Test, batch_size=3072, shuffle=True, drop_last = True, num_workers=4, pin_memory = False)    \n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 5.e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20], gamma=0.5)\n",
    "    \n",
    "    model = model.to(\"cuda\")\n",
    "    \n",
    "\n",
    "\n",
    "    import wandb\n",
    "    wandb.login(key=\"cb53927c12bd57a0d943d2dedf7881cfcdcc8f09\")\n",
    "    wandb.init(\n",
    "        project = \"Trash\",\n",
    "        name = \"Literature_code\"\n",
    "    )\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    #--------------------------\n",
    "    wandb.watch(model, log_freq=50)\n",
    "    #---------------------------\n",
    "    w_intr = 1000\n",
    "\n",
    "    for epoch in range(30):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        train_steps = 0\n",
    "        test_steps = 0\n",
    "        label_list = []\n",
    "        outputs_list = []\n",
    "        train_auc = 0\n",
    "        test_auc = 0\n",
    "        model.train()\n",
    "        for image, label in tqdm(dataloader_train):\n",
    "            image = image.to(\"cuda\")\n",
    "            label = label.to(\"cuda\")\n",
    "            #optimizer.zero_grad()\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "              outputs = model(image)\n",
    "              loss = criterion(outputs, label.float())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "            if train_steps%w_intr == 0:\n",
    "                 wandb.log({\"loss\": loss.item()})\n",
    "        with torch.no_grad():\n",
    "            label_list = straightner(label_list)\n",
    "            outputs_list = straightner(outputs_list)\n",
    "            train_auc = metric(label_list, outputs_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #-------------------------------------------------------------------\n",
    "        model.eval()\n",
    "        label_list = []\n",
    "        outputs_list = []\n",
    "        with torch.no_grad():\n",
    "            for image, label in tqdm(dataloader_test):\n",
    "                image = image.to(\"cuda\")\n",
    "                label = label.to(\"cuda\")\n",
    "                outputs = model(image)\n",
    "                loss = criterion(outputs, label.float())\n",
    "                label_list.append(label.detach().cpu().numpy())\n",
    "                outputs_list.append(outputs.detach().cpu().numpy())\n",
    "                val_loss += loss.item()\n",
    "                test_steps +=1\n",
    "                if test_steps%w_intr == 0:\n",
    "                 wandb.log({\"val_loss\": loss.item()})\n",
    "            label_list = straightner(label_list)\n",
    "            outputs_list = straightner(outputs_list)\n",
    "            test_auc = metric(label_list, outputs_list)\n",
    "\n",
    "        train_loss = train_loss/train_steps\n",
    "        val_loss = val_loss/ test_steps\n",
    "    #     hist_loss_train.append(train_loss)\n",
    "    #     hist_loss_test.append(val_loss)\n",
    "    #     hist_auc_train.append(train_auc)\n",
    "    #     hist_auc_test.append(test_auc)\n",
    "\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print(\"Epoch No\" , epoch)\n",
    "        print(\"The Training loss of the epoch, \",train_loss)\n",
    "        print(\"The Training AUC of the epoch,  %.3f\"%train_auc)\n",
    "        print(\"The validation loss of the epoch, \",val_loss)\n",
    "        print(\"The validation AUC of the epoch, %.3f\"%test_auc)\n",
    "        print(\"----------------------------------------------------\")\n",
    "    #     PATH = \"model.pt\"\n",
    "    #     torch.save({\n",
    "    #             'epoch': epoch,\n",
    "    #             'model_state_dict': model.state_dict(),\n",
    "    #             'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #             'scheduler': scheduler.state_dict()\n",
    "    #             }, PATH)\n",
    "        lr_scheduler.step()\n",
    "        curr_lr = lr_scheduler._last_lr[0]\n",
    "        wandb.log({\"Train_auc_epoch\": train_auc,\n",
    "                  \"Epoch\": epoch,\n",
    "                  \"Val_auc_epoch\": test_auc,\n",
    "                  \"Train_loss_epoch\": train_loss,\n",
    "                  \"Val_loss_epoch\": val_loss,\n",
    "                  \"Lr\": curr_lr}\n",
    "                 )\n",
    "        gc.collect()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be47d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdc250601\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ML_RTC/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ML_RTC\\Desktop\\Diptarko Choudhury\\Dataset_Finder\\Try-3\\wandb\\run-20220707_190952-p52s376o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dc250601/Trash/runs/p52s376o\" target=\"_blank\">Literature_code</a></strong> to <a href=\"https://wandb.ai/dc250601/Trash\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fff2c288c34ab0bd711831afc3a916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52833f703d974ffe9d92c6929960161c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:10<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Epoch No 0\n",
      "The Training loss of the epoch,  0.6744130021995969\n",
      "The Training AUC of the epoch,  0.624\n",
      "The validation loss of the epoch,  0.6503037611643473\n",
      "The validation AUC of the epoch, 0.671\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cf487c6b954f6098471c32fe7d756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:09<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d37a96a39c4ed3b8b6389bb28cf955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Epoch No 1\n",
      "The Training loss of the epoch,  0.6434347911013497\n",
      "The Training AUC of the epoch,  0.679\n",
      "The validation loss of the epoch,  0.6331052117877536\n",
      "The validation AUC of the epoch, 0.697\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51294addb547471fa53b2ad90baec78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea56a00fdd24b5cbd3914fe418a254d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"starting training\")\n",
    "coat()\n",
    "print(\"Training completed\")\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
