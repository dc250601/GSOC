{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663ffa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0141b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.downsample = out_channels//in_channels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=self.downsample, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=self.downsample)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample > 1:\n",
    "            residual = self.shortcut(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, nblocks, fmaps):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.fmaps = fmaps\n",
    "        self.nblocks = nblocks\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels, fmaps[0], kernel_size=7, stride=2, padding=1)\n",
    "        self.layer1 = self.block_layers(self.nblocks, [fmaps[0],fmaps[0]])\n",
    "        self.layer2 = self.block_layers(1, [fmaps[0],fmaps[1]])\n",
    "        self.layer3 = self.block_layers(self.nblocks, [fmaps[1],fmaps[1]])\n",
    "        self.fc = nn.Linear(fmaps[1], 1)\n",
    "        #self.FCN = nn.Sequential(\n",
    "        #        nn.Linear(fmaps[1], 128), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        #        nn.Linear(128, 128), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        #        nn.Linear(128, 128), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        #        nn.Linear(128, 3)\n",
    "        #        )\n",
    "        \n",
    "    def block_layers(self, nblocks, fmaps):\n",
    "        layers = []\n",
    "        for _ in range(nblocks):\n",
    "            layers.append(ResBlock(fmaps[0], fmaps[1]))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size=x.size()[2:])\n",
    "        x = x.view(x.size()[0], self.fmaps[1])\n",
    "        x = self.fc(x)\n",
    "        #x = self.FCN(x)\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d39919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return auc\n",
    "\n",
    "def straightner(a):\n",
    "    A = np.zeros((a[0].shape[0]*len(a)))\n",
    "    start_index = 0\n",
    "    end_index = 0\n",
    "    for i in range(len(a)):\n",
    "        start_index = i*a[0].shape[0]\n",
    "        end_index = start_index+a[0].shape[0]\n",
    "        A[start_index:end_index] = a[i]\n",
    "    return A\n",
    "\n",
    "def predictor(outputs):\n",
    "    return np.argmax(outputs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e58d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(3, 3, [16, 32])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((125,125)),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.RandomVerticalFlip(),\n",
    "                            transforms.RandomRotation(20),\n",
    "                            transforms.ToTensor()\n",
    "                           ])\n",
    "test_transform = transforms.Compose([transforms.Resize((125,125)),\n",
    "                            transforms.ToTensor()\n",
    "                           ])\n",
    "\n",
    "\n",
    "dataset_Train = datasets.ImageFolder('./Quark_Gluon_Mini/Train/', transform=train_transform)\n",
    "dataset_Test = datasets.ImageFolder('./Quark_Gluon_Mini/Test/', transform =test_transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_Train, batch_size=128, shuffle=True, drop_last = True, num_workers=0, pin_memory = False)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_Test, batch_size=128, shuffle=True, drop_last = True, num_workers=0, pin_memory = False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f40172",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5.e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20], gamma=0.5)\n",
    "\n",
    "model = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835fac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"cb53927c12bd57a0d943d2dedf7881cfcdcc8f09\")\n",
    "wandb.init(\n",
    "    project = \"Trash_\",\n",
    "    name = \"Literature_code\"\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "#--------------------------\n",
    "wandb.watch(model, log_freq=50)\n",
    "#---------------------------\n",
    "w_intr = 1000\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_steps = 0\n",
    "    test_steps = 0\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    train_auc = 0\n",
    "    test_auc = 0\n",
    "    model.train()\n",
    "    for image, label in tqdm(dataloader_train):\n",
    "        image = image.to(\"cuda\")\n",
    "        label = label.to(\"cuda\")\n",
    "        #optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        outputs = model(image[:,0,:,:].unsqueeze(1))\n",
    "        loss = criterion(outputs, label.float())\n",
    "        label_list.append(label.detach().cpu().numpy())\n",
    "        outputs_list.append(outputs.detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "        if train_steps%w_intr == 0:\n",
    "             wandb.log({\"loss\": loss.item()})\n",
    "    with torch.no_grad():\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        train_auc = metric(label_list, outputs_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, label in tqdm(dataloader_test):\n",
    "            image = image.to(\"cuda\")\n",
    "            label = label.to(\"cuda\")\n",
    "            outputs = model(image[:,0,:,:].unsqueeze(1))\n",
    "            loss = criterion(outputs, label.float())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "            outputs_list.append(outputs.detach().cpu().numpy())\n",
    "            val_loss += loss.item()\n",
    "            test_steps +=1\n",
    "            if test_steps%w_intr == 0:\n",
    "             wandb.log({\"val_loss\": loss.item()})\n",
    "        label_list = straightner(label_list)\n",
    "        outputs_list = straightner(outputs_list)\n",
    "        test_auc = metric(label_list, outputs_list)\n",
    "\n",
    "    train_loss = train_loss/train_steps\n",
    "    val_loss = val_loss/ test_steps\n",
    "#     hist_loss_train.append(train_loss)\n",
    "#     hist_loss_test.append(val_loss)\n",
    "#     hist_auc_train.append(train_auc)\n",
    "#     hist_auc_test.append(test_auc)\n",
    "\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Epoch No\" , epoch)\n",
    "    print(\"The Training loss of the epoch, \",train_loss)\n",
    "    print(\"The Training AUC of the epoch,  %.3f\"%train_auc)\n",
    "    print(\"The validation loss of the epoch, \",val_loss)\n",
    "    print(\"The validation AUC of the epoch, %.3f\"%test_auc)\n",
    "    print(\"----------------------------------------------------\")\n",
    "#     PATH = \"model.pt\"\n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'scheduler': scheduler.state_dict()\n",
    "#             }, PATH)\n",
    "    lr_scheduler.step()\n",
    "    curr_lr = lr_scheduler._last_lr[0]\n",
    "    wandb.log({\"Train_auc_epoch\": train_auc,\n",
    "              \"Epoch\": epoch,\n",
    "              \"Val_auc_epoch\": test_auc,\n",
    "              \"Train_loss_epoch\": train_loss,\n",
    "              \"Val_loss_epoch\": val_loss,\n",
    "              \"Lr\": curr_lr}\n",
    "             )\n",
    "    gc.collect()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "50e8044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(dataloader_train))\n",
    "images = images.to(\"cuda\")\n",
    "labels = labels.to(\"cuda\")\n",
    "output = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1864a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(output, labels.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ecdd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a283cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27311.4648, device='cuda:0',\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5941b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "33ddcf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-37053.7891, -58470.0234, -46584.9219, -42151.0859, -39857.3477,\n",
       "        -58215.3203, -45163.8242, -65805.0703, -49551.3594, -35920.8008,\n",
       "        -53223.2891, -59897.6484, -56235.8086, -40992.0391, -44947.9336,\n",
       "        -43326.3477, -76288.3125, -50752.7812, -57017.9102, -38822.5195,\n",
       "        -39978.5156, -52022.8164, -36821.5859, -49700.0195, -43267.5977,\n",
       "        -49274.7461, -53484.2461, -40105.6016, -59079.1875, -53305.0000,\n",
       "        -50406.0547, -50172.9844, -97722.7500, -38522.1992, -54185.2578,\n",
       "        -42274.0547, -44518.0391, -53565.1328, -37947.0586, -37659.1367,\n",
       "        -68229.4844, -52011.0312, -44492.3359, -67162.2109, -44757.2773,\n",
       "        -40536.3203, -59534.0469, -49588.8047, -40495.5547, -52991.8320,\n",
       "        -64703.0625, -43687.5195, -47974.8828, -35663.2773, -38176.5039,\n",
       "        -33539.9023, -38790.5469, -53741.0391, -42099.4062, -67782.8828,\n",
       "        -46462.1484, -52750.8906, -35765.3867, -60213.2031, -49455.6289,\n",
       "        -51277.3477, -50426.6602, -60714.0078, -40961.3594, -53925.6445,\n",
       "        -38420.9219, -47953.6562, -53569.7891, -46013.5547, -52947.2266,\n",
       "        -81252.3750, -50580.3633, -38503.5234, -72680.8281, -40082.4141,\n",
       "        -54582.1875, -43612.8750, -43732.6875, -74992.4844, -36719.9570,\n",
       "        -47237.8359, -93142.9375, -43676.6445, -59567.2734, -46023.8711,\n",
       "        -40095.5898, -57151.9375, -37384.2383, -45534.3125, -44553.2617,\n",
       "        -51172.4219, -45093.8555, -40405.7070, -37097.3984, -40938.2578,\n",
       "        -52657.6562, -45936.9805, -49872.7344, -53780.6523, -38546.2461,\n",
       "        -46985.6602, -61893.3438, -43637.8242, -53046.4648, -43881.8555,\n",
       "        -46204.1289, -54040.8359, -60697.1445, -40323.0117, -40904.2617,\n",
       "        -46083.3477, -48095.0039, -39759.9570, -46236.5195, -44459.5273,\n",
       "        -75642.3047, -53061.6016, -43522.1836, -64299.1875, -51761.2109,\n",
       "        -49379.7773, -43848.9609, -47401.6836], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
